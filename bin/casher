#!/usr/bin/env ruby
require 'timeout'
require 'shellwords'
require 'fileutils'
require 'yaml'
require 'uri'

class Casher
  include FileUtils

  CURL_FORMAT = <<-EOF
     time_namelookup:  %%{time_namelookup} s
        time_connect:  %%{time_connect} s
     time_appconnect:  %%{time_appconnect} s
    time_pretransfer:  %%{time_pretransfer} s
       time_redirect:  %%{time_redirect} s
  time_starttransfer:  %%{time_starttransfer} s
      speed_download:  %%{speed_download} bytes/s
                     ----------
          time_total:  %%{time_total} s
  EOF

  def initialize
    @casher_dir = ENV['CASHER_DIR'] || File.expand_path(".casher", ENV["HOME"])
    @mtime_file = File.expand_path('mtime.yml', @casher_dir)
    @checksum_file = File.expand_path('md5sums', @casher_dir)
    @fetch_tar  = File.expand_path('fetch.tbz', @casher_dir)
    @push_tar   = File.expand_path('push.tbz', @casher_dir)
    @paths_file = File.expand_path('paths', @casher_dir)
    @mtimes     = File.exist?(@mtime_file) ? YAML.load_file(@mtime_file) : {}
    @timeout    = Integer(ENV['CASHER_TIME_OUT'] || 3*60)

    mkdir_p @casher_dir
  end

  def run(command, *arguments)
    raise "unknown command" unless %w[fetch add push].include? command
    Timeout.timeout(@timeout) { send(command, *arguments) }
  rescue TimeoutError
    line  = "casher #{command}"
    line += Shellwords.join(arguments) if command == "add"
    $stderr.puts "running `#{line}` took longer than #{@timeout} seconds and has been aborted"
  end

  def fetch(*urls)
    puts "attempting to download cache archive"
    archive_found = false
    urls.each do |url|
      puts "fetching #{%r(([^/]+?/[^/]+?)(\?.*)?$).match(url)[1]}"

      @fetch_tar  = File.expand_path('fetch.tgz', @casher_dir) if path_ext(url) == 'tgz'

      if system "curl --tcp-nodelay -w '#{CURL_FORMAT}' %p -o %p -f -s --retry 3 >#{@casher_dir}/fetch.log 2>#{@casher_dir}/fetch.err.log" % [url, @fetch_tar]
        puts "found cache"
        archive_found = true
        break
      end
    end
    unless archive_found
      puts "could not download cache"
      if File.exist? @fetch_tar
        rm @fetch_tar
      end
    end
  end

  def add(*paths)
    expanded_paths = paths.map { |p| File.expand_path(p) }
    expanded_paths.each do |path|
      path = File.expand_path(path)
      puts "adding #{path} to cache"
      mkdir_p path

      if fetched_archive
        tar(:x, fetched_archive, path) { puts "#{path} is not yet cached" }
      end

      @mtimes[path] = Time.now.to_i
    end

    if md5deep_available?
      File.open(@paths_file, 'a') { |f| f << expanded_paths.join("\n") << "\n" }
      system "md5deep -r #{expanded_paths.join(' ')} >> #{@checksum_file}"
    else
      File.open(@mtime_file, 'w') { |f| f << @mtimes.to_yaml }
    end

  end

  def push(url)
    if changed?
      puts "changes detected, packing new archive"

      @push_tar  = File.expand_path('push.tgz', @casher_dir) if path_ext(url) == 'tgz'

      tar(:c, @push_tar, *cached_directories)
      puts "uploading archive"
      unless system "curl -T %p %p -s -S  >#{@casher_dir}/push.log 2>#{@casher_dir}/push.err.log" % [@push_tar, url]
        puts "failed to upload cache", File.read("#{@casher_dir}/push.err.log"), File.read("#{@casher_dir}/push.log")
      end
    else
      puts "nothing changed, not updating cache"
    end
  end

  def changed?
    return true unless fetched_archive

    if md5deep_available?
      paths = File.read(@paths_file).gsub("\n", ' ')
      return true if File.size(@checksum_file) == 0
      md5deep_check_output = `md5deep -x #{@checksum_file} -r #{paths}`
      if md5deep_check_output.length > 0
        puts "change detected\n#{md5deep_check_output}"
        return true
      else
        return false
      end
    end

    @mtimes.any? do |path, mtime|
      Dir.glob("#{path}/**/*").any? do |file|
        next if File.mtime(file).to_i <= mtime
        next if File.directory?(file)
        puts "change detected: #{file}"
        true
      end
    end
  end

  def tar(flag, file, *args, &block)
    compression_flag = file.end_with?('.tbz') ? 'j' : 'z'

    command = "tar -P#{compression_flag}#{flag}f #{Shellwords.escape(file)} #{Shellwords.join(args)}"
    block ||= proc { puts "FAILED: #{command}", File.read("#{@casher_dir}/tar.err.log"), File.read("#{@casher_dir}/tar.log") }
    block.call unless system "#{command} 2>#{@casher_dir}/tar.err.log >#{@casher_dir}/tar.log"
  end

  def path_ext(url)
    path = URI.split(url)[5]
    path.split('.').last
  end

  def fetched_archive
    [ File.expand_path('fetch.tbz', @casher_dir), File.expand_path('fetch.tgz', @casher_dir) ].find do |f|
      File.exist? f
    end
  end

  def md5deep_available?
    @md5deep_available ||= system("which md5deep >/dev/null 2>&1")
  end

  def cached_directories
    if File.exist?(@paths_file)
      File.read(@paths_file).split("\n").compact
    else
      @mtimes.keys
    end
  end
end

Casher.new.run(*ARGV) if $0 == __FILE__
